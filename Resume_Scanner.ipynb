{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume_Scanner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYj47qdUj12Yiicn6TNma2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlitzenPrancer/Resume-Scanner-in-Python/blob/main/Resume_Scanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1Mj1THyjrSV",
        "outputId": "b8b0a54f-bb08-4f8e-c821-422b14bc35c9"
      },
      "source": [
        "!pip install docx2txt\n",
        "import docx2txt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOubjKjRsmKB"
      },
      "source": [
        "job_description = docx2txt.process('/content/sample_data/sample_description.docx')\n",
        "resume = docx2txt.process('/content/sample_data/sample_resume2.docx' )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVtHR8nhtZTR",
        "outputId": "9dc26dd6-1c2b-498f-b068-c0a0e63a1dd9"
      },
      "source": [
        "print(resume)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Brandon Thomas, Data Scientist\n",
            "\n",
            "323 Knob Hill Apt. G\n",
            "San Francisco, CA 00000\n",
            "415.555.1212 | email@gmail.com\n",
            "www.dataminer.com\n",
            "\n",
            "\n",
            "\n",
            "Professional Profile\n",
            "\n",
            "A former Ruby and Java programmer with newly acquired skills, an insatiable intellectual curiosity, and the ability to mine hidden gems located within large sets of structured, semi-structured and unstructured data. Able to leverage a heavy dose of mathematics and applied statistics with visualization and a healthy sense of exploration.\n",
            "\n",
            "Education\n",
            "\n",
            "Grad Certificate, Data Mining 2012University of California, San Diego\n",
            "Relevant Courses: Data Mining Methods and Techniques, Data Preparation for Data\n",
            "Mining and Advanced Methods and Applications\n",
            "B.S. Computer Science 2009San Francisco State University\n",
            "\n",
            "Core Competencies\n",
            "\n",
            "Strategic Thinking: Able to influence the strategic direction of the company by identifying opportunities in large, rich data sets and creating and implementing data driven strategies that fuel growth including revenue and profits.\n",
            "\n",
            "Modeling: Design and implement statistical / predictive models and cutting edge algorithms utilizing diverse sources of data to predict demand, risk and price elasticity. Experience with creating ETL processes to source and link data.\n",
            "\n",
            "Analytics: Utilize analytical applications like SAS to identify trends and relationships between different pieces of data, draw appropriate conclusions and translate analytical findings into risk management and marketing strategies that drive value.\n",
            "\n",
            "Drive Enhancements: Develop tools and reports that help users access and analyze data resulting in higher revenues and margins and a better customer experience.\n",
            "\n",
            "Communications and Project Management: Capable of turning dry analysis into an exciting story that influences the direction of the business and communicating with diverse teams to take a project from start to finish. Collaborate with product teams to develop and support our internal data platform and to support ongoing analyses.\n",
            "\n",
            "Skills and Tools\n",
            "\n",
            "■NoSQL data stores (Cassandra, MongoDB)\n",
            "■Hadoop, MySQL, Big Table, MapReduce, SAS\n",
            "■Large-scale, distributed systems design and development\n",
            "■Scaling, performance and scheduling and ETL techniques\n",
            "■C, C++, Java, Ruby on Rails\n",
            "\n",
            "Experience\n",
            "\n",
            "Cool Jeans    San Francisco, CA\n",
            "\n",
            "Data Analyst2012-present\n",
            "\n",
            "Work closely with various teams across the company to identify and solve business challenges utilizing large structured, semi-structured, and unstructured data in a distributed processing environment. Develop a new pricing strategy for Total Jeans that boosted margins by 2 percent and analyzed customer buying habits which correctly predicated the resurgence of dark blue denim giving us a jump on the competition.\n",
            "\n",
            "■Analyze large datasets to provide strategic direction to the company.\n",
            "■Perform quantitative analysis of product sales trends to recommend pricing decisions.\n",
            "■Conduct cost and benefit analysis on new ideas.\n",
            "■Scrutinize and track customer behavior to identify trends and unmet needs.\n",
            "■Develop statistical models to forecast inventory and procurement cycles.\n",
            "■Assist in developing internal tools for data analysis.\n",
            "\n",
            "Programmer   2010-2011\n",
            "\n",
            "■Coded, tested, debugged, implemented and documented apps using Java and Ruby.\n",
            "■Developed eCommerce solutions and social networking functionality.\n",
            "■Designed, developed and maintained eCommerce and social networking applications.\n",
            "■Built report interfaces and data feeds.\n",
            "■Gathered and collected information from various programs, analyzed time requirements and prepared documentation to change existing programs.\n",
            "\n",
            "Professional Affiliations and Education\n",
            "\n",
            "NoSQL and Big Data Conference2013\n",
            "Hadoop Hackathon: Learn Map Reduce2013\n",
            "Member, Silicon Valley Big Data Meetup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMvVFdqitjY4"
      },
      "source": [
        "content = [job_description, resume]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHP2aEwLttRs"
      },
      "source": [
        "# converting text to vectors using count vectorizer\n",
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "# fitting list \"content\" into CountVectorizer\n",
        "# this converts all the text present in the files to vector\n",
        "matrix = cv.fit_transform(content)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZprSZTGxu_qt"
      },
      "source": [
        "# to find the similarity we are using cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity(matrix)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW9sqTKyvbyo",
        "outputId": "0d058da3-a45b-4bef-f8dd-b62ddc0bed59"
      },
      "source": [
        "# printing similarity matrix\n",
        "print(similarity_matrix)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.86832248]\n",
            " [0.86832248 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wxzCkxxvpX8",
        "outputId": "64cdaab0-a4c6-4b96-8ad0-44c56fc08235"
      },
      "source": [
        "print('Resume matches by '+ str(similarity_matrix[1][0]*100) + '% percentage')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resume matches by 86.83224793701768% percentage\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}